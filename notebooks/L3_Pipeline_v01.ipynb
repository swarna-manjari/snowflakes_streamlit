{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e979e6bc-f9ba-41ab-8bb6-aca0a1548fd5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2abac8a-f1d4-45d1-b665-5cf34f702bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37db0a73-d787-4e9f-9df7-5813bfec5b53",
   "metadata": {},
   "source": [
    "### Gcloud auth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80cf3145-7c37-4a31-9764-7873b938d571",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.auth import default\n",
    "from google.auth.transport.requests import Request\n",
    "from google.auth.exceptions import DefaultCredentialsError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86ce057a-7bb0-4efb-87c7-0070e3a597d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"GOOGLE_API_KEY\" in os.environ:\n",
    "    del os.environ[\"GOOGLE_API_KEY\"]\n",
    "    print(\" Removed GOOGLE_API_KEY to use Vertex AI instead\")\n",
    "\n",
    "# Set environment variables for Vertex AI\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = \"dataplatr-sandbox\"\n",
    "os.environ[\"GOOGLE_CLOUD_LOCATION\"] = \"us-central1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5147c40b-6fc4-4a85-909f-1832c79bfdcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ADC credentials found!\n",
      "   Credential type: Credentials\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"True\"\n",
    "\n",
    "# Verify ADC is available\n",
    "try:\n",
    "    from google.auth import default\n",
    "    credentials, project = default()\n",
    "    print(f\" ADC credentials found!\")\n",
    "    print(f\"   Credential type: {type(credentials).__name__}\")\n",
    "except Exception as e:\n",
    "    print(f\" ADC error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b4e7739-830c-40d2-984a-1b4ed5cda8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import textwrap\n",
    "import asyncio\n",
    "from typing import Optional, Tuple\n",
    "from pydantic import BaseModel, Field\n",
    "import gradio as gr\n",
    "import uuid\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdf94291-34d4-49a0-9ba7-1b2bf286aab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.context import get_active_session\n",
    "from snowflake.snowpark.exceptions import SnowparkSQLException\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark.functions import col "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e723f37e-71c2-4e77-ac22-a79fa9941118",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.genai.types import ThinkingConfig, GenerateContentConfig\n",
    "from google.adk.planners import BuiltInPlanner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fe1ac7-ce38-4206-9a4b-aeac7edc66f2",
   "metadata": {},
   "source": [
    "### Generation Configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fc92f59-07e1-41ab-baac-f86480ad6d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "safety_settings = [\n",
    "    types.SafetySetting(\n",
    "        category=types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "        threshold=types.HarmBlockThreshold.OFF,\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66b56758-4a61-44f1-859f-838e29ff3d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_content_config = types.GenerateContentConfig(\n",
    "   safety_settings=safety_settings,\n",
    "   temperature=0,\n",
    "   max_output_tokens=8192,\n",
    "   top_p=0.95,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98fa369f-6577-4a48-9ac0-5b22809940e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertex AI client initialized\n"
     ]
    }
   ],
   "source": [
    "genai_client = genai.Client(\n",
    "    vertexai=True,\n",
    "    project=\"dataplatr-sandbox\",\n",
    "    location=\"us-central1\"\n",
    ")\n",
    "\n",
    "print(\"Vertex AI client initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c206aca8-44f7-4078-a9f9-70f57d913455",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PATH\"] += os.pathsep + r\"C:\\Users\\pooja\\AppData\\Local\\Google\\Cloud SDK\\google-cloud-sdk\\bin\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92e8a948-3e4d-4825-befe-b2e592aee97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pooja\\AppData\\Local\\Google\\Cloud SDK\\google-cloud-sdk\\bin\\gcloud.CMD\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "print(shutil.which(\"gcloud\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c92ce9cb-23a8-4894-9bc3-207b2a58dfa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Checking GCP Authentication (Python SDK)...\n",
      "============================================================\n",
      " Credentials found but may need refresh.\n",
      " Refreshed successfully.\n",
      " Project ID: dataplatr-sandbox\n",
      "============================================================\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "def check_gcp_authentication_native():\n",
    "    \n",
    "    \"\"\"Check GCP authentication using google.auth library.\"\"\"\n",
    "    \n",
    "    print(\" Checking GCP Authentication (Python SDK)...\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    try:\n",
    "        # Try loading ADC credentials\n",
    "        credentials, project_id = default()\n",
    "\n",
    "        if credentials and credentials.valid:\n",
    "            print(\" Application Default Credentials found and valid!\")\n",
    "        else:\n",
    "            print(\" Credentials found but may need refresh.\")\n",
    "            credentials.refresh(Request())\n",
    "            print(\" Refreshed successfully.\")\n",
    "\n",
    "        print(f\" Project ID: {project_id or 'Unknown'}\")\n",
    "        print(\"=\" * 60)\n",
    "        return True\n",
    "\n",
    "    except DefaultCredentialsError:\n",
    "        print(\" No valid Application Default Credentials found.\")\n",
    "        print(\" Run this command to authenticate:\")\n",
    "        print(\"   gcloud auth application-default login\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error verifying authentication: {e}\")\n",
    "    finally:\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "    return False\n",
    "\n",
    "# Run test\n",
    "gcp_auth_ok = check_gcp_authentication_native()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "530b9791-5556-4a99-a454-06f99512efc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AIzaSyA3imT3fHzZobQCw1ZBPDqgLbU1GjjGNP0'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"GOOGLE_API_KEY\") or \"AIzaSyA3imT3fHzZobQCw1ZBPDqgLbU1GjjGNP0\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1852a23-fbeb-417f-b2fa-4a4194183e08",
   "metadata": {},
   "source": [
    "### Global variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb732ee4-a545-4019-97e6-d69363cc3e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "APP_NAME = \"reporting_layer_app\"\n",
    "USER_ID = \"test_user_23\"\n",
    "SESSION_ID = \"session123\"\n",
    "MODEL_NAME = \"snowflake-arctic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a199b1d1-ce6f-41e2-8c29-2e849be21154",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_DB =\"DATAPLATR_DEMO\"\n",
    "L2_SCHEMA = \"DWH_SI\" \n",
    "L3_SCHEMA = \"L3_SI\"   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84c0a34-dd33-44c4-8323-a8cf6896641e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Github Configs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd5b7ec0-b034-44e3-8fa2-226aa4c39b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "git_repo_url=\"https://github.com/poojapapney/snf_elt.git\"\n",
    "GITHUB_REPO = \"poojapapney/snf_elt\"\n",
    "BRANCH=\"PP-Test\"\n",
    "GITHUB_TOKEN=\"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002f0f6e-7135-436b-beb8-e1be32160930",
   "metadata": {},
   "source": [
    "### Snowflake Connection Set up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "164682c6-02e4-49b8-bf10-88bd5426dc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global snf session variable :\n",
    "\n",
    "SNOWFLAKE_SESSION = None\n",
    "\n",
    "\n",
    "def init_snowflake_session(target_db: str, target_schema: str):\n",
    "    \"\"\"\n",
    "    Initializes or retrieves a global Snowflake session.\n",
    "    Works in both Snowflake-native and local environments.\n",
    "    \"\"\"\n",
    "    global SNOWFLAKE_SESSION\n",
    "\n",
    "    if SNOWFLAKE_SESSION is not None:\n",
    "        \n",
    "        print(\" Reusing existing Snowflake session.\")\n",
    "        \n",
    "        return SNOWFLAKE_SESSION\n",
    "\n",
    "    try:\n",
    "        # Try to use active Snowflake Notebook session:\n",
    "        \n",
    "        SNOWFLAKE_SESSION = get_active_session()\n",
    "        print(\"  Successfully connected to active Snowflake session.\")\n",
    "    except Exception: # if not\n",
    "        print(\"  No active session found. Creating a new session for local development...\")\n",
    "\n",
    "        with open(\"configs.json\", \"r\") as f:\n",
    "            connection_parameters = json.load(f)\n",
    "\n",
    "        SNOWFLAKE_SESSION = Session.builder.configs(connection_parameters).create()\n",
    "        print(\"  Successfully created a new local Snowflake session.\")\n",
    "\n",
    "    # Set database and schema context:\n",
    "    \n",
    "    SNOWFLAKE_SESSION.use_database(target_db)\n",
    "    SNOWFLAKE_SESSION.use_schema(target_schema)\n",
    "\n",
    "    print(f\" Session active with DB: {target_db}, Schema: {target_schema}\")\n",
    "    return SNOWFLAKE_SESSION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25baec9b-0ad8-4d90-983a-58fe6e1a16ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  No active session found. Creating a new session for local development...\n"
     ]
    },
    {
     "ename": "DatabaseError",
     "evalue": "250001 (08001): Failed to connect to DB: ORQIFID-LB06580.snowflakecomputing.com:443. Your free trial has ended and all of your virtual warehouses have been suspended. Add billing information in the Snowflake web UI to continue using the full set of Snowflake features.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mSnowparkSessionException\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36minit_snowflake_session\u001b[39m\u001b[34m(target_db, target_schema)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     20\u001b[39m     \u001b[38;5;66;03m# Try to use active Snowflake Notebook session:\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     SNOWFLAKE_SESSION = \u001b[43mget_active_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m  Successfully connected to active Snowflake session.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\snf_env\\Lib\\site-packages\\snowflake\\snowpark\\context.py:110\u001b[39m, in \u001b[36mget_active_session\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Returns the current active Snowpark session.\u001b[39;00m\n\u001b[32m    104\u001b[39m \n\u001b[32m    105\u001b[39m \u001b[33;03mRaises: SnowparkSessionException: If there is more than one active session or no active sessions.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    108\u001b[39m \u001b[33;03m    A :class:`Session` object for the current session.\u001b[39;00m\n\u001b[32m    109\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msnowflake\u001b[49m\u001b[43m.\u001b[49m\u001b[43msnowpark\u001b[49m\u001b[43m.\u001b[49m\u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_active_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\snf_env\\Lib\\site-packages\\snowflake\\snowpark\\session.py:328\u001b[39m, in \u001b[36m_get_active_session\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m SnowparkClientExceptionMessages.SERVER_NO_DEFAULT_SESSION()\n",
      "\u001b[31mSnowparkSessionException\u001b[39m: (1403): No default Session is found. Please create a session before you call function 'udf' or use decorator '@udf'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mDatabaseError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m SNOWFLAKE_SESSION= \u001b[43minit_snowflake_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTARGET_DB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mL2_SCHEMA\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36minit_snowflake_session\u001b[39m\u001b[34m(target_db, target_schema)\u001b[39m\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mconfigs.json\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     28\u001b[39m         connection_parameters = json.load(f)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     SNOWFLAKE_SESSION = \u001b[43mSession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnection_parameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m  Successfully created a new local Snowflake session.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Set database and schema context:\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\snf_env\\Lib\\site-packages\\snowflake\\snowpark\\session.py:520\u001b[39m, in \u001b[36mSession.SessionBuilder.create\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    518\u001b[39m     _add_session(session)\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m520\u001b[39m     session = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconnection\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._app_name:\n\u001b[32m    523\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._format_json:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\snf_env\\Lib\\site-packages\\snowflake\\snowpark\\session.py:562\u001b[39m, in \u001b[36mSession.SessionBuilder._create_internal\u001b[39m\u001b[34m(self, conn)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mparamstyle\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._options:\n\u001b[32m    560\u001b[39m     \u001b[38;5;28mself\u001b[39m._options[\u001b[33m\"\u001b[39m\u001b[33mparamstyle\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mqmark\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    561\u001b[39m new_session = Session(\n\u001b[32m--> \u001b[39m\u001b[32m562\u001b[39m     ServerConnection({}, conn) \u001b[38;5;28;01mif\u001b[39;00m conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mServerConnection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_options\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    563\u001b[39m     \u001b[38;5;28mself\u001b[39m._options,\n\u001b[32m    564\u001b[39m )\n\u001b[32m    566\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mpassword\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._options:\n\u001b[32m    567\u001b[39m     \u001b[38;5;28mself\u001b[39m._options[\u001b[33m\"\u001b[39m\u001b[33mpassword\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\snf_env\\Lib\\site-packages\\snowflake\\snowpark\\_internal\\server_connection.py:168\u001b[39m, in \u001b[36mServerConnection.__init__\u001b[39m\u001b[34m(self, options, conn)\u001b[39m\n\u001b[32m    166\u001b[39m \u001b[38;5;28mself\u001b[39m._lower_case_parameters = {k.lower(): v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m options.items()}\n\u001b[32m    167\u001b[39m \u001b[38;5;28mself\u001b[39m._add_application_parameters()\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m \u001b[38;5;28mself\u001b[39m._conn = conn \u001b[38;5;28;01mif\u001b[39;00m conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_lower_case_parameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[38;5;28mself\u001b[39m.max_string_size = DEFAULT_STRING_SIZE\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._conn._session_parameters:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\snf_env\\Lib\\site-packages\\snowflake\\connector\\__init__.py:66\u001b[39m, in \u001b[36mConnect\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(SnowflakeConnection.\u001b[34m__init__\u001b[39m)\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mConnect\u001b[39m(**kwargs) -> SnowflakeConnection:\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSnowflakeConnection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\snf_env\\Lib\\site-packages\\snowflake\\connector\\connection.py:588\u001b[39m, in \u001b[36mSnowflakeConnection.__init__\u001b[39m\u001b[34m(self, connection_name, connections_file_path, **kwargs)\u001b[39m\n\u001b[32m    586\u001b[39m     kwargs = _get_default_connection_params()\n\u001b[32m    587\u001b[39m \u001b[38;5;28mself\u001b[39m.__set_error_attributes()\n\u001b[32m--> \u001b[39m\u001b[32m588\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    589\u001b[39m \u001b[38;5;28mself\u001b[39m._telemetry = TelemetryClient(\u001b[38;5;28mself\u001b[39m._rest)\n\u001b[32m    590\u001b[39m \u001b[38;5;28mself\u001b[39m.expired = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\snf_env\\Lib\\site-packages\\snowflake\\connector\\connection.py:972\u001b[39m, in \u001b[36mSnowflakeConnection.connect\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    970\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(exceptions_dict))\n\u001b[32m    971\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m972\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__open_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\snf_env\\Lib\\site-packages\\snowflake\\connector\\connection.py:1371\u001b[39m, in \u001b[36mSnowflakeConnection.__open_connection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1363\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1364\u001b[39m     \u001b[38;5;66;03m# okta URL, e.g., https://<account>.okta.com/\u001b[39;00m\n\u001b[32m   1365\u001b[39m     \u001b[38;5;28mself\u001b[39m.auth_class = AuthByOkta(\n\u001b[32m   1366\u001b[39m         application=\u001b[38;5;28mself\u001b[39m.application,\n\u001b[32m   1367\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.login_timeout,\n\u001b[32m   1368\u001b[39m         backoff_generator=\u001b[38;5;28mself\u001b[39m._backoff_generator,\n\u001b[32m   1369\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1371\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauthenticate_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauth_class\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[38;5;28mself\u001b[39m._password = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# ensure password won't persist\u001b[39;00m\n\u001b[32m   1374\u001b[39m \u001b[38;5;28mself\u001b[39m.auth_class.reset_secrets()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\snf_env\\Lib\\site-packages\\snowflake\\connector\\connection.py:1704\u001b[39m, in \u001b[36mSnowflakeConnection.authenticate_with_retry\u001b[39m\u001b[34m(self, auth_instance)\u001b[39m\n\u001b[32m   1701\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mauthenticate_with_retry\u001b[39m(\u001b[38;5;28mself\u001b[39m, auth_instance) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1702\u001b[39m     \u001b[38;5;66;03m# make some changes if needed before real __authenticate\u001b[39;00m\n\u001b[32m   1703\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1704\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_authenticate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mauth_instance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1705\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ReauthenticationRequest \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[32m   1706\u001b[39m         \u001b[38;5;66;03m# cached id_token expiration error, we have cleaned id_token and try to authenticate again\u001b[39;00m\n\u001b[32m   1707\u001b[39m         logger.debug(\u001b[33m\"\u001b[39m\u001b[33mID token expired. Reauthenticating...: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, ex)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\snf_env\\Lib\\site-packages\\snowflake\\connector\\connection.py:1736\u001b[39m, in \u001b[36mSnowflakeConnection._authenticate\u001b[39m\u001b[34m(self, auth_instance)\u001b[39m\n\u001b[32m   1734\u001b[39m auth_instance._retry_ctx.set_start_time()\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[43mauth\u001b[49m\u001b[43m.\u001b[49m\u001b[43mauthenticate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1737\u001b[39m \u001b[43m        \u001b[49m\u001b[43mauth_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1738\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccount\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maccount\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1739\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1740\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1741\u001b[39m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1742\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwarehouse\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwarehouse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1743\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrole\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrole\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpasscode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_passcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1745\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpasscode_in_password\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_passcode_in_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1746\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmfa_callback\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mfa_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1747\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpassword_callback\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_password_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1748\u001b[39m \u001b[43m        \u001b[49m\u001b[43msession_parameters\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_session_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1749\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m OperationalError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1751\u001b[39m     logger.debug(\n\u001b[32m   1752\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mOperational Error raised at authentication\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1753\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfor authenticator: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(auth_instance).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1754\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\snf_env\\Lib\\site-packages\\snowflake\\connector\\auth\\_auth.py:401\u001b[39m, in \u001b[36mAuth.authenticate\u001b[39m\u001b[34m(self, auth_instance, account, user, database, schema, warehouse, role, passcode, passcode_in_password, mfa_callback, password_callback, session_parameters, timeout)\u001b[39m\n\u001b[32m    397\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(auth_instance, AuthByUsrPwdMfa):\n\u001b[32m    398\u001b[39m         \u001b[38;5;28mself\u001b[39m._delete_temporary_credential(\n\u001b[32m    399\u001b[39m             \u001b[38;5;28mself\u001b[39m._rest._host, user, TokenType.MFA_TOKEN\n\u001b[32m    400\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     \u001b[43mError\u001b[49m\u001b[43m.\u001b[49m\u001b[43merrorhandler_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_rest\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43mDatabaseError\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmsg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFailed to connect to DB: \u001b[39;49m\u001b[38;5;132;43;01m{host}\u001b[39;49;00m\u001b[33;43m:\u001b[39;49m\u001b[38;5;132;43;01m{port}\u001b[39;49;00m\u001b[33;43m. \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{message}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    408\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m                \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_rest\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m                \u001b[49m\u001b[43mport\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_rest\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_port\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mret\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43merrno\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mER_FAILED_TO_CONNECT_TO_DB\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msqlstate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mSQLSTATE_CONNECTION_WAS_NOT_ESTABLISHED\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    418\u001b[39m     logger.debug(\n\u001b[32m    419\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtoken = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    420\u001b[39m         (\n\u001b[32m   (...)\u001b[39m\u001b[32m    424\u001b[39m         ),\n\u001b[32m    425\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\snf_env\\Lib\\site-packages\\snowflake\\connector\\errors.py:286\u001b[39m, in \u001b[36mError.errorhandler_wrapper\u001b[39m\u001b[34m(connection, cursor, error_class, error_value)\u001b[39m\n\u001b[32m    263\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34merrorhandler_wrapper\u001b[39m(\n\u001b[32m    265\u001b[39m     connection: SnowflakeConnection | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    268\u001b[39m     error_value: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[32m    269\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    270\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Error handler wrapper that calls the errorhandler method.\u001b[39;00m\n\u001b[32m    271\u001b[39m \n\u001b[32m    272\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    283\u001b[39m \u001b[33;03m        exception to the first handler in that order.\u001b[39;00m\n\u001b[32m    284\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     handed_over = \u001b[43mError\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhand_to_other_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    292\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m handed_over:\n\u001b[32m    293\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m Error.errorhandler_make_exception(\n\u001b[32m    294\u001b[39m             error_class,\n\u001b[32m    295\u001b[39m             error_value,\n\u001b[32m    296\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\snf_env\\Lib\\site-packages\\snowflake\\connector\\errors.py:344\u001b[39m, in \u001b[36mError.hand_to_other_handler\u001b[39m\u001b[34m(connection, cursor, error_class, error_value)\u001b[39m\n\u001b[32m    342\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m     \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43merrorhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    345\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\snf_env\\Lib\\site-packages\\snowflake\\connector\\errors.py:217\u001b[39m, in \u001b[36mError.default_errorhandler\u001b[39m\u001b[34m(connection, cursor, error_class, error_value)\u001b[39m\n\u001b[32m    215\u001b[39m errno = error_value.get(\u001b[33m\"\u001b[39m\u001b[33merrno\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    216\u001b[39m done_format_msg = error_value.get(\u001b[33m\"\u001b[39m\u001b[33mdone_format_msg\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m error_class(\n\u001b[32m    218\u001b[39m     msg=error_value.get(\u001b[33m\"\u001b[39m\u001b[33mmsg\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    219\u001b[39m     errno=\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m errno \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mint\u001b[39m(errno),\n\u001b[32m    220\u001b[39m     sqlstate=error_value.get(\u001b[33m\"\u001b[39m\u001b[33msqlstate\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    221\u001b[39m     sfqid=error_value.get(\u001b[33m\"\u001b[39m\u001b[33msfqid\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    222\u001b[39m     query=error_value.get(\u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    223\u001b[39m     done_format_msg=(\n\u001b[32m    224\u001b[39m         \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m done_format_msg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(done_format_msg)\n\u001b[32m    225\u001b[39m     ),\n\u001b[32m    226\u001b[39m     connection=connection,\n\u001b[32m    227\u001b[39m     cursor=cursor,\n\u001b[32m    228\u001b[39m )\n",
      "\u001b[31mDatabaseError\u001b[39m: 250001 (08001): Failed to connect to DB: ORQIFID-LB06580.snowflakecomputing.com:443. Your free trial has ended and all of your virtual warehouses have been suspended. Add billing information in the Snowflake web UI to continue using the full set of Snowflake features."
     ]
    }
   ],
   "source": [
    "SNOWFLAKE_SESSION= init_snowflake_session(TARGET_DB, L2_SCHEMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1999eb27-32db-420e-9433-bc0f72ef998f",
   "metadata": {},
   "source": [
    "### Gold Layer Agentic Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e493764-ee42-4f4f-b039-fc1762455200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tables_context(database: str, schema: str) -> list:\n",
    "    \"\"\"\n",
    "    List all base tables in the given schema with their descriptions.\n",
    "\n",
    "    Returns:\n",
    "        list of dicts, each containing:\n",
    "        - table_id: fully qualified name\n",
    "        - description: table comment or empty string\n",
    "    \"\"\"\n",
    "    \n",
    "    if SNOWFLAKE_SESSION is None:\n",
    "        \n",
    "        raise ValueError(\"No active Snowflake session. Please call init_snowflake_session() first.\")\n",
    "\n",
    "    try:\n",
    "        query = f\"\"\"\n",
    "            SELECT TABLE_CATALOG AS DATABASE_NAME,\n",
    "                   TABLE_SCHEMA,\n",
    "                   TABLE_NAME,\n",
    "                   TABLE_TYPE,\n",
    "                   COMMENT AS DESCRIPTION\n",
    "            FROM {database}.INFORMATION_SCHEMA.TABLES\n",
    "            WHERE TABLE_SCHEMA = '{schema}'\n",
    "              AND TABLE_TYPE = 'BASE TABLE'\n",
    "            ORDER BY TABLE_NAME\n",
    "        \"\"\"\n",
    "\n",
    "        df = SNOWFLAKE_SESSION.sql(query).to_pandas()\n",
    "\n",
    "        candidates = [\n",
    "            {\n",
    "                \"table_id\": f\"{row.DATABASE_NAME}.{row.TABLE_SCHEMA}.{row.TABLE_NAME}\",\n",
    "                \"description\": row.DESCRIPTION or \"\"\n",
    "            }\n",
    "            for _, row in df.iterrows()\n",
    "        ]\n",
    "\n",
    "        return candidates\n",
    "\n",
    "    except Exception as e:\n",
    "        return [{\"error\": f\"Failed to list tables for {database}.{schema}: {e}\"}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacaf221-f6cb-43b2-85cd-3c5c63450674",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_TEMPLATE = f\"\"\"{{{{ config(\n",
    "    materialized='table' ,\n",
    "     schema='{L3_SCHEMA}'\n",
    ")}}}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda69eae-c814-4dbb-b60c-1b8e957d76d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discover_table_schema_snowflake(table_path: str) -> dict:\n",
    "    \n",
    "    \"\"\"\n",
    "    Discover Snowflake table schema and sample values.\n",
    "    \"\"\"\n",
    "    global SNOWFLAKE_SESSION\n",
    "    \n",
    "    if SNOWFLAKE_SESSION is None or not hasattr(SNOWFLAKE_SESSION, \"sql\"):\n",
    "        \n",
    "        raise ValueError(\"Snowflake session not initialized. Please call init_snowflake_session() first.\")\n",
    "\n",
    "    db, sch, tbl = table_path.split(\".\")\n",
    "\n",
    "    try:\n",
    "        cols_df = SNOWFLAKE_SESSION.sql(f\"\"\"\n",
    "            SELECT COLUMN_NAME, DATA_TYPE, COMMENT\n",
    "            FROM {db}.INFORMATION_SCHEMA.COLUMNS\n",
    "            WHERE TABLE_SCHEMA = '{sch}'\n",
    "              AND TABLE_NAME = '{tbl}'\n",
    "            ORDER BY ORDINAL_POSITION\n",
    "        \"\"\").to_pandas()\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        \n",
    "        return {\"error\": f\"Failed to fetch schema for {table_path}: {e}\"}\n",
    "\n",
    "    schema_info = [\n",
    "        {\n",
    "            \"name\": row[\"COLUMN_NAME\"],\n",
    "            \"type\": row[\"DATA_TYPE\"],\n",
    "            \"description\": row[\"COMMENT\"] or \"\",\n",
    "            \"sample_values\": []\n",
    "        }\n",
    "        for _, row in cols_df.iterrows()\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        df = SNOWFLAKE_SESSION.sql(f\"SELECT * FROM {table_path} SAMPLE (0.01) LIMIT 5\").to_pandas()\n",
    "        \n",
    "        for col in df.columns:\n",
    "            \n",
    "            values = df[col].dropna().astype(str).unique().tolist()[:5]\n",
    "            \n",
    "            for col_info in schema_info:\n",
    "                \n",
    "                if col_info[\"name\"] == col:\n",
    "                    \n",
    "                    col_info[\"sample_values\"] = values\n",
    "                    \n",
    "                    break\n",
    "    except Exception as e:\n",
    "        \n",
    "        print(f\"Could not fetch sample values for {table_path}: {e}\")\n",
    "\n",
    "    return {\"table\": table_path, \"columns\": schema_info}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123793e4-8247-41af-92fa-a64358f4ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_approved_tables_schema(approved_tables: list, database: str, schema: str) -> list:\n",
    "    \"\"\"\n",
    "    Fetch schema metadata and sample values for approved Snowflake tables.\n",
    "    \"\"\"\n",
    "    if not approved_tables:\n",
    "        raise ValueError(\"approved_tables list is empty.\")\n",
    "\n",
    "    all_schemas = [\n",
    "        discover_table_schema_snowflake(f\"{database}.{schema}.{table}\")\n",
    "        for table in approved_tables\n",
    "    ]\n",
    "    return all_schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b95265-4f25-4956-9d8c-e89aa41c1dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def validate_sql(sql: str) -> dict:\n",
    "#     global SNOWFLAKE_SESSION\n",
    "\n",
    "#     if SNOWFLAKE_SESSION is None:\n",
    "#         raise ValueError(\"No active Snowflake session. Please call init_snowflake_session() first.\")\n",
    "\n",
    "#     try:\n",
    "#         # Wrap in try/except to catch missing columns/tables\n",
    "#         test_sql = f\"SELECT * FROM ({sql}) LIMIT 0\"\n",
    "#         SNOWFLAKE_SESSION.sql(test_sql).collect()\n",
    "#         return {\"status\": \"valid\", \"message\": \"SQL is syntactically and semantically valid.\"}\n",
    "#     except Exception as e:\n",
    "#         return {\"status\": \"invalid\", \"error\": str(e), \"sql_snippet\": sql}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e97b139-9bd3-4d77-bf65-f1b012f6cdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_sql(sql: str) -> str:\n",
    "    \"\"\"\n",
    "    Validate a SQL query in Snowflake using EXPLAIN/LIMIT 0 approach.\n",
    "    Always returns a valid JSON string.\n",
    "    \"\"\"\n",
    "    global SNOWFLAKE_SESSION\n",
    "\n",
    "    try:\n",
    "        # Run a validation query:\n",
    "        \n",
    "        test_sql = f\"SELECT * FROM ({sql}) LIMIT 0\"\n",
    "        SNOWFLAKE_SESSION.sql(test_sql).collect()\n",
    "\n",
    "        result = {\n",
    "            \"status\": \"valid\",\n",
    "            \"message\": \" SQL is syntactically and semantically valid.\"\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        result = {\n",
    "            \"status\": \"invalid\",\n",
    "            \"error\": str(e),\n",
    "            \"trace\": traceback.format_exc(limit=2),\n",
    "            \"sql_snippet\": sql[:300]\n",
    "        }\n",
    "\n",
    "    # For JSON output:\n",
    "    \n",
    "    try:\n",
    "        return json.dumps(result, ensure_ascii=False)\n",
    "    except Exception as e:\n",
    "        \n",
    "        # Fallback if serialization somehow fails:\n",
    "        \n",
    "        return json.dumps({\n",
    "            \"status\": \"error\",\n",
    "            \"message\": f\"Serialization failed: {e}\",\n",
    "            \"fallback_result\": str(result)\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5943e08b-c6ed-448e-848b-0febff0117ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_schema(session, database_name: str, schema_name: str):\n",
    "    \"\"\"Checks if a schema exists and creates it if not.\"\"\"\n",
    "    schema_ref = f'\"{database_name}\".\"{schema_name}\"'\n",
    "    try:\n",
    "        session.sql(f'USE DATABASE \"{database_name}\"').collect()\n",
    "        session.sql(f\"DESC SCHEMA {schema_ref}\").collect()\n",
    "        print(f\"Schema {schema_ref} already exists.\")\n",
    "    except SnowparkSQLException as e:\n",
    "        if \"does not exist\" in str(e).lower():\n",
    "            print(f\"Schema {schema_ref} not found. Creating...\")\n",
    "            session.sql(f\"CREATE SCHEMA IF NOT EXISTS {schema_ref}\").collect()\n",
    "            print(f\"Schema {schema_ref} created successfully.\")\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "\n",
    "ensure_schema(SNOWFLAKE_SESSION, TARGET_DB, L3_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2b132a-57a0-411a-9059-f3c2466b2e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_model_json(raw_text: str):\n",
    "    # Remove markdown fences if present\n",
    "    cleaned = re.sub(r\"^```json|```$\", \"\", raw_text.strip(), flags=re.MULTILINE).strip()\n",
    "    return json.loads(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1828ed77-a8a1-48c9-805a-aa3a80107705",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOOL_REGISTRY = {\n",
    "    'get_approved_tables_schema': get_approved_tables_schema,\n",
    "    'validate_sql': validate_sql\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928ab92e-ce53-4f25-afed-482e896041b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_TABLES_DESCRIPTION = get_tables_context(TARGET_DB, L2_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2a3d69-09b6-4c43-b318-2767d19a74d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_TABLES_DESCRIPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab52231-9c6f-454f-9182-fe5557b0451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "L3_Agent = LlmAgent(\n",
    "\n",
    "    model=MODEL_NAME,\n",
    "\n",
    "    name=\"L3_Agent\",\n",
    "\n",
    "    description=\"Assistant to create L3 tables in ELT process\",\n",
    "\n",
    "    instruction=f\"\"\"\n",
    "    Follow the following steps:\n",
    "    1) Gather requirement from user for logic of L3 table creation. Ask clarification questions if needed.\n",
    "    2) See how requirement can be met from the AVAILABLE TABLES OF L2 given below:\n",
    "    3) If confused, ask for clarification which tables and fields to use.\n",
    "    4) For L3 table creation first discuss the table logic in natural language in a crisp way with the user.\n",
    "    5) For tables to be used get the columns and their description from get_approved_tables_schema tool only. Do NOT suggest generic field names but the ones from the actual tables.\n",
    "    6) If the user confirms the table logic in natural language then create sql code for it and give it in a different part in output..\n",
    "    7) Once the user confirms the sql code validate it by giving it a run in snowflake using validate_sql tool.\n",
    "    8) If the validation of sql fails then handle it accordingly. Always confirm the results of validation to user.\n",
    "    9) Use the tools from the {TOOL_REGISTRY} only.\n",
    "    10) There is a sql code editor on the right. So if some message in a part comes like `Manually updated latest SQL:` then it means that you have to take this updated code as it has been manually changed by the user in the editor.\n",
    "    11) If there is some change requested by the user in the sql code then always generate the full updated sql and not just the edited part.\n",
    "    12) If the user wants to write the sql into dbt as a model then ask them to press the button on the right.\n",
    "    13) User has very less time. Always keep the output text concise but always be complete in information.\n",
    "\n",
    "    Response Formatting Rules:\n",
    "    \n",
    "    1. When asking questions or confirming table logic  respond in plain text.\n",
    "    2. When showing SQL code  wrap the SQL inside triple backticks, like:\\n\n",
    "    \"```sql\\nSELECT ...\\n```\\n\"\n",
    "    3. When confirming validation results  always write a short natural-language summary (e.g. : SQL is valid or  Validation failed).\\n\"\n",
    "    4. While making a tool call, always add a short line in natural language explaining the act.\n",
    "\n",
    "    Output Instructions:\n",
    "    Give sql code in a different Part wrappend in ```sql (code) ``` .\n",
    "\n",
    "    AVAILABLE TABLES OF L2:\n",
    "    {L2_TABLES_DESCRIPTION}\n",
    "\n",
    "    \"\"\",\n",
    "\n",
    "    tools=[\n",
    "       get_approved_tables_schema,\n",
    "        validate_sql\n",
    "    ],\n",
    "\n",
    "    generate_content_config=types.GenerateContentConfig(\n",
    "        temperature=0,\n",
    "        max_output_tokens=8192\n",
    "     \n",
    "    ),\n",
    "\n",
    "    # Define structured output schema :\n",
    "\n",
    "    # output_schema=L3RequirementOutput,\n",
    "    output_key=\"l3_requirement\"\n",
    ")\n",
    "\n",
    "print(f\"Agent '{L3_Agent.name}' created using model '{MODEL_NAME}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be01a389-f970-4e26-9d00-feda8a337d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_service = InMemorySessionService()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b17f847-edf6-4689-ad36-27e33dd6e4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner_l3 = Runner(agent=L3_Agent, app_name=APP_NAME, session_service=session_service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d92318-ca9d-40ff-ae63-884c529d8715",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Chat Session Manager \n",
    "\n",
    "class ChatSession:\n",
    "    def __init__(self):\n",
    "        self.code_state = \"\"   # stores SQL code\n",
    "        self.history = []     # stores chat history\n",
    "\n",
    "    def update_code_state(self, code):\n",
    "        self.code_state = code.strip()\n",
    "        return f\"SQL Code state updated ({len(code)} characters)\"\n",
    "\n",
    "chat_session = ChatSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed39e938-4019-4df5-817e-d5e0ea35300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session has to be created in the running cell as it is the part of the event loop and awaits on the agent.\n",
    "\n",
    "await session_service.create_session(\n",
    "    app_name=APP_NAME,\n",
    "    user_id=USER_ID,\n",
    "    session_id=SESSION_ID\n",
    ")\n",
    "\n",
    "async def chat_with_agent(message, history, session_id, current_code_state=None):\n",
    "    parts = []\n",
    "    parts.append(types.Part(text=message))\n",
    "\n",
    "    if current_code_state.strip() != chat_session.code_state:\n",
    "        parts.append(types.Part(text=f\"Manually updated latest SQL:\\n{current_code_state.strip()}\"))\n",
    "        chat_session.code_state = current_code_state.strip()\n",
    "\n",
    "    next_message = types.Content(\n",
    "        role=\"user\",\n",
    "        parts=parts\n",
    "    )\n",
    "\n",
    "    response_text = \"\"\n",
    "    raw_response_text = \"\"\n",
    "    sql_generated = None\n",
    "    made_tool_call = False\n",
    "\n",
    "    async for event in runner_l3.run_async(\n",
    "        user_id=USER_ID,\n",
    "        session_id=session_id,\n",
    "        new_message=next_message\n",
    "    ):\n",
    "        # Agent text output:\n",
    "\n",
    "        if getattr(event, \"content\", None) and getattr(event.content, \"parts\", None):\n",
    "            \n",
    "            for part in event.content.parts:\n",
    "                if hasattr(part, \"text\") and part.text:\n",
    "                    # Collect normal agent text\n",
    "                    response_text += part.text.strip() + \"\\n\"\n",
    "\n",
    "                    # Capture SQL blocks if present:\n",
    "                    \n",
    "                    if '```sql' in part.text:\n",
    "                        sql_generated = part.text.split('```sql')[1].split('```')[0].strip()\n",
    "\n",
    "                elif hasattr(part, \"function_call\") and part.function_call:\n",
    "                    made_tool_call = True\n",
    "                    func_name = getattr(part.function_call, \"name\", None)\n",
    "                    if func_name:\n",
    "                        print(f\" Tool called: {func_name}\")\n",
    "                    else:\n",
    "                        print(\" Tool call part received (no name yet)\")\n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "        # if getattr(event, \"content\", None) and getattr(event.content, \"parts\", None):\n",
    "        #     text_parts = [\n",
    "        #         p.text for p in event.content.parts\n",
    "        #         if hasattr(p, \"text\") and p.text is not None\n",
    "        #     ]\n",
    "        #     for agent_text in text_parts:\n",
    "\n",
    "        #       raw_response_text += agent_text\n",
    "        #       if '``sql' in agent_text:\n",
    "        #         sql_generated = agent_text.split('`sql')[1].split('``')[0]\n",
    "        #       else:\n",
    "        #         response_text += agent_text + \"\\n\"\n",
    "                    \n",
    "                  \n",
    "    # If response text is empty:   # change\n",
    "    \n",
    "    if not response_text.strip():\n",
    "        if made_tool_call:\n",
    "            response_text = \"(Agent made a tool call  waiting for results...)\"\n",
    "        else:\n",
    "            response_text = \"(No response generated. Please try rephrasing or check your SQL editor.)\"\n",
    "        \n",
    "    \n",
    "\n",
    "    history.append({\"role\": \"user\", \"content\": message})\n",
    "    history.append({\"role\": \"assistant\", \"content\": response_text.strip()})\n",
    "\n",
    "    # Save generated SQL as base_code\n",
    "    if sql_generated:\n",
    "        chat_session.code_state = sql_generated.strip()\n",
    "\n",
    "    return history, chat_session.code_state\n",
    "\n",
    "async def write_to_dbt(current_code_state, history):\n",
    "    \"\"\"\n",
    "    Writes the current SQL code to a dbt L3 model and commits it to GitHub.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure a message is returned even if SQL is empty:\n",
    "    \n",
    "    if not current_code_state or not current_code_state.strip():\n",
    "        message = {\"role\": \"assistant\", \"content\": \"Cannot write empty SQL.\"}\n",
    "        history.append(message)\n",
    "        return history\n",
    "\n",
    "    #  Update chat session code state:\n",
    "    \n",
    "    chat_session.code_state = current_code_state.strip()\n",
    "\n",
    "    raw_sql = chat_session.code_state\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Convert the following SQL query into dbt-compatible jinja sql model syntax.\n",
    "\n",
    "    Rules:\n",
    "    - Replace FROM and JOIN table references with the dbt ref() function.\n",
    "      Example: FROM project.dataset.table -> FROM {{{{ref('table')}}}}\n",
    "    - Keep indentation and SQL formatting clean.\n",
    "    - Do not change SQL code, keep it as is.\n",
    "    - Return only SQL code (no explanations).\n",
    "\n",
    "    SQL:\n",
    "    {raw_sql}\n",
    "\n",
    "    OUTPUT_FORMAT:\n",
    "    {{\n",
    "      \"sqlx\": ...(sqlx code here)...\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Sending SQL to Gemini for transformation...\")\n",
    "\n",
    "    try:\n",
    "        response = genai_client.models.generate_content(\n",
    "        model=\"gemini-2.5-pro\",\n",
    "        contents=prompt,\n",
    "        config=types.GenerateContentConfig(\n",
    "            temperature=0,\n",
    "            max_output_tokens=8192,\n",
    "            response_mime_type=\"application/json\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "        raw_sql_json = response.text\n",
    "        parsed = parse_model_json(raw_sql_json)\n",
    "        sql = parsed[\"sqlx\"]\n",
    "        # filename = parsed[\"filename\"]\n",
    "\n",
    "        try:\n",
    "            formatted_sql = sqlparse.format(sql, reindent=True, keyword_case=\"upper\")\n",
    "            print(formatted_sql)\n",
    "        except Exception:\n",
    "            formatted_sql = sql\n",
    "\n",
    "        transformed_sql = formatted_sql\n",
    "        print(\"Gemini transformed SQL successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        transformed_sql = raw_sql\n",
    "        history.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": f\"Gemini transformation failed, using raw SQL. Error: {e}\"\n",
    "        })\n",
    "\n",
    "    #  Attach dbt config block on top:\n",
    "    \n",
    "    sql_content = CONFIG_TEMPLATE.strip() + \"\\n\\n\" + transformed_sql\n",
    "    sqlx_content = sql_content.strip()\n",
    "\n",
    "    if sqlx_content[-1] == ';':\n",
    "      sqlx_content = sqlx_content[:-1]\n",
    "        \n",
    "    # Define folder and filenames\n",
    "    folder = \"models/gold\"\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    file_name = \"Balance_Sheet_Summary\"\n",
    "    sql_path = f\"{folder}/{file_name}.sql\"\n",
    "    yaml_path = f\"{folder}/{file_name}.yml\"\n",
    "\n",
    "    # Build YAML metadata (optional, basic structure)\n",
    "    yaml_content = textwrap.dedent(f\"\"\"\\\n",
    "    version: 2\n",
    "\n",
    "    models:\n",
    "      - name: {file_name}\n",
    "        description: \"Auto-generated L3 dbt model from agent\"\n",
    "        columns: []\n",
    "    \"\"\")\n",
    "\n",
    "    #  GitHub commit details :\n",
    "    \n",
    "    github_repo = GITHUB_REPO\n",
    "    github_token = GITHUB_TOKEN\n",
    "    branch = BRANCH\n",
    "\n",
    "    if not github_token:\n",
    "        error_text = \"GitHub token not found. Please set GITHUB_TOKEN environment variable.\"\n",
    "        history.append({\"role\": \"assistant\", \"content\": error_text})\n",
    "        return history\n",
    "\n",
    "    headers = {\"Authorization\": f\"token {github_token}\"}\n",
    "    api_base = f\"https://api.github.com/repos/{github_repo}\"\n",
    "\n",
    "    #  Get the latest branch SHA:\n",
    "    \n",
    "    branch_info = requests.get(f\"{api_base}/git/refs/heads/{branch}\", headers=headers).json()\n",
    "    base_sha = branch_info[\"object\"][\"sha\"]\n",
    "\n",
    "    #  Create a new Git tree:\n",
    "    \n",
    "    tree = [\n",
    "        {\n",
    "            \"path\": sql_path,\n",
    "            \"mode\": \"100644\",\n",
    "            \"type\": \"blob\",\n",
    "            \"content\": sql_content,\n",
    "        },\n",
    "        {\n",
    "            \"path\": yaml_path,\n",
    "            \"mode\": \"100644\",\n",
    "            \"type\": \"blob\",\n",
    "            \"content\": yaml_content,\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    tree_resp = requests.post(\n",
    "        f\"{api_base}/git/trees\",\n",
    "        headers=headers,\n",
    "        json={\"base_tree\": base_sha, \"tree\": tree},\n",
    "    ).json()\n",
    "    new_tree_sha = tree_resp[\"sha\"]\n",
    "\n",
    "    # Create a commit:\n",
    "    \n",
    "    commit_message = f\"Auto-generated L3 model: {file_name}.sql\"\n",
    "    commit_resp = requests.post(\n",
    "        f\"{api_base}/git/commits\",\n",
    "        headers=headers,\n",
    "        json={\"message\": commit_message, \"tree\": new_tree_sha, \"parents\": [base_sha]},\n",
    "    ).json()\n",
    "    new_commit_sha = commit_resp[\"sha\"]\n",
    "\n",
    "    #  Update the branch reference:\n",
    "    \n",
    "    requests.patch(\n",
    "        f\"{api_base}/git/refs/heads/{branch}\",\n",
    "        headers=headers,\n",
    "        json={\"sha\": new_commit_sha},\n",
    "    )\n",
    "\n",
    "    response_text = f\"Successfully wrote L3 model `{file_name}.sql` to dbt repo `{github_repo}` on branch `{branch}`.\"\n",
    "    history.append({\"role\": \"assistant\", \"content\": response_text})\n",
    "    return history\n",
    "    \n",
    "# Gradio UI:\n",
    "\n",
    "with gr.Blocks(title=\"L3 Agent App\") as demo:\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=2):\n",
    "            gr.Markdown(\"# L3 Layer Agent\")\n",
    "            chatbot = gr.Chatbot(label=\"L3 Agent\", type=\"messages\")\n",
    "            user_input = gr.Textbox(placeholder=\"Type your requirement...\", label=\"Message\")\n",
    "\n",
    "        with gr.Column(scale=1):\n",
    "            gr.Markdown(\"# SQL Generator (dbt)\")\n",
    "            sql_editor = gr.Code(language=\"sql\", label=\"SQL Editor\", value=\"\", interactive=True)\n",
    "            write_btn = gr.Button(\"Write to dbt Repo\")\n",
    "\n",
    "    #  Respond handler:\n",
    "    \n",
    "    async def respond(message, history, current_code_state):\n",
    "        print(message, history, current_code_state)\n",
    "        history, code_state = await chat_with_agent(message, history, SESSION_ID, current_code_state)\n",
    "        return history, code_state, \"\"\n",
    "\n",
    "    #  Gradio Event Bindings :\n",
    "    \n",
    "    user_input.submit(\n",
    "        respond,\n",
    "        [user_input, chatbot, sql_editor],\n",
    "        [chatbot, sql_editor, user_input]\n",
    "    )\n",
    "\n",
    "    write_btn.click(\n",
    "        fn=write_to_dbt,\n",
    "        inputs=[sql_editor, chatbot],\n",
    "        outputs=[chatbot]\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607faba3-3fc0-404f-9306-21c26dc63174",
   "metadata": {},
   "source": [
    "### Execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5acf3a-5be4-4535-88fb-5af1de8bfc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Launch:\n",
    "\n",
    "demo.launch(share=True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0529cb-8d8b-46ba-ae36-33276c6eb6b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python snf-env",
   "language": "python",
   "name": "snf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
